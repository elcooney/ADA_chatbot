{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for loading PDF documents and QA chain.\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "# Store the API key in a variable.\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = \"embedded_resources/\"\n",
    "\n",
    "# Get all files in the folder and add them to a list\n",
    "file_list = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# Print the list of files\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_qa_chatbot(query):\n",
    "    all_documents = []\n",
    "\n",
    "    for file in file_list:\n",
    "        full_path = os.path.join(folder_path, file)\n",
    "        if os.path.exists(full_path):\n",
    "            pdf_loader = PyPDFLoader(full_path)\n",
    "            documents = pdf_loader.load()\n",
    "            all_documents.extend(documents)\n",
    "        else:\n",
    "            print(f\"Warning: file not found - {full_path}\")\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(google_api_key=GEMINI_API_KEY, model=GEMINI_MODEL, temperature=0.0)\n",
    "\n",
    "    chain = load_qa_chain(llm)\n",
    "\n",
    "    result = chain.invoke({\"input_documents\": all_documents, \"question\": query})\n",
    "    return result[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elcoo\\anaconda3\\Lib\\site-packages\\gradio\\analytics.py:102: UserWarning: IMPORTANT: You are using gradio version 5.0.0, however version 5.0.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elcoo\\AppData\\Local\\Temp\\ipykernel_31572\\1695826883.py:15: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  chain = load_qa_chain(llm)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Gradio Interface application function with parameters. \n",
    "app = gr.Interface(fn=ada_qa_chatbot, \n",
    "                   title=\"American Disabilities Act Chatbot\",\n",
    "                   description=\"Ask the chatbot about the ADA requirements per '2021 Accessibility Pocketbook 2021 IBC速, 2021 IEBC速 and ICC A117.1-2017'.\",\n",
    "                   inputs=[\"text\"], \n",
    "                   outputs=gr.Textbox(lines=20, label=\"Summarized Response\", show_copy_button=True))\n",
    "# Launch the app\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_conversation_chatbot(query, chat_history=[]):\n",
    "    # Initialize the document store if it doesn't exist\n",
    "    if not hasattr(ada_conversation_chatbot, 'vectorstore'):\n",
    "        all_documents = []\n",
    "        for file in file_list:\n",
    "            full_path = os.path.join(folder_path, file)\n",
    "            if os.path.exists(full_path):\n",
    "                pdf_loader = PyPDFLoader(full_path)\n",
    "                documents = pdf_loader.load()\n",
    "                all_documents.extend(documents)\n",
    "            else:\n",
    "                print(f\"Warning: file not found - {full_path}\")\n",
    "\n",
    "        # Split documents into chunks\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "        texts = text_splitter.split_documents(all_documents)\n",
    "\n",
    "        # Create embeddings and vector store\n",
    "        embeddings = HuggingFaceEmbeddings()\n",
    "        ada_conversation_chatbot.vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "    # Initialize or retrieve memory\n",
    "    if not hasattr(ada_conversation_chatbot, 'memory'):\n",
    "        ada_conversation_chatbot.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = ChatGoogleGenerativeAI(google_api_key=GEMINI_API_KEY, model=GEMINI_MODEL, temperature=0.0)\n",
    "\n",
    "    # Create ConversationalRetrievalChain\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm,\n",
    "        retriever=ada_conversation_chatbot.vectorstore.as_retriever(),\n",
    "        memory=ada_conversation_chatbot.memory\n",
    "    )\n",
    "\n",
    "    # Get the response\n",
    "    result = chain({\"question\": query})\n",
    "    \n",
    "    # Update chat history\n",
    "    chat_history.append((query, result['answer']))\n",
    "\n",
    "    return result['answer'], chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the Gradio interface\n",
    "app = gr.Interface(\n",
    "    fn=ada_conversation_chatbot,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, label=\"Your Question\"),\n",
    "        gr.State([])  # For storing chat history\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(lines=20, label=\"Response\", show_copy_button=True),\n",
    "        gr.State()  # For updating chat history\n",
    "    ],\n",
    "    title=\"American Disabilities Act Chatbot\",\n",
    "    description=\"Ask the chatbot about the ADA requirements per '2021 Accessibility Pocketbook 2021 IBC速, 2021 IEBC速 and ICC A117.1-2017'.\",\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
